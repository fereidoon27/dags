# ‚ö†Ô∏è IMPORTANT: Use Version 2 (v2) - All Issues Fixed

## üéØ What Happened

You reported **4 critical issues** with the first version. I've created **Version 2 (v2)** that fixes ALL of them.

## üì¶ Files to Use

### ‚úÖ USE THESE (Version 2):
1. **ha_service_health_monitor_enhanced_v2.py** ‚≠ê - The corrected DAG (use this!)
2. **V2_FIXES_SUMMARY.md** - Detailed explanation of all fixes
3. **AIRFLOW_LOGS_EXPLAINED.md** - Understanding Airflow log structure

### üìö Supporting Documentation (Still Valid):
4. **DEPLOYMENT_GUIDE.md** - Deployment instructions
5. **TIMEZONE_CONFIGURATION_GUIDE.md** - Timezone setup guide
6. **QUICK_REFERENCE.md** - Incident response cheat sheet

### ‚ùå DON'T USE THIS (Version 1 - Has Bugs):
- ~~ha_service_health_monitor_enhanced.py~~ (v1 - has issues)

---

## üêõ What Was Fixed in v2

### Issue 1: NFS Active/Passive Logic ‚úÖ FIXED
**Problem:** Services on active NFS node were not being checked correctly
**Fix:** Changed from default parameter to dynamic argument passing

```python
# BEFORE (v1 - WRONG):
def check_nfs_service(service_name=service, host=hostname, active_nfs_node=active_nfs):
    # active_nfs_node received the task object, not the value!

# AFTER (v2 - CORRECT):
def check_nfs_service(active_nfs_node: str, service_name=service, host=hostname):
    # Now gets actual value like "nfs-2"
    
# Call correctly:
nfs_tasks.append(check_nfs_service(active_nfs))  # Dynamic argument
active_nfs >> nfs_tasks  # Proper dependency
```

### Issue 2: Schedule & Log Duration ‚úÖ FIXED
**Your request:** 2-minute monitoring with last 2 minutes of logs
**Fix:** 
```python
schedule='*/2 * * * *'  # Changed from */15
minutes_back=2          # Changed from 60
```

### Issue 3: Enhanced Task Tracing ‚úÖ IMPLEMENTED
**Your request:** Trace task instances across all system logs with unique identifiers
**Fix:** Added comprehensive task identifier extraction and cross-component log searching

```python
def get_task_identifiers():
    """Extracts: dag_id, task_id, run_id, job_id, external_executor_id, PID, ti_key, etc."""

def fetch_task_specific_logs(identifiers):
    """Searches all schedulers and workers for logs mentioning this specific task"""
```

### Issue 4: Timestamp "[Invalid date]" ‚úÖ FIXED
**Problem:** Grep on journalctl was mixing timestamp formats
**Fix:** 
```python
# Use ISO format for consistent timestamps
journalctl -u service --since '2 minutes ago' --no-pager -o short-iso
# Format: 2025-10-28T15:00:27+0330 (includes timezone)
```

**Plus:** Fixed execution_date deprecation warnings

---

## üöÄ Quick Deployment (v2)

```bash
# 1. Deploy v2 to active NFS node
scp ha_service_health_monitor_enhanced_v2.py rocky@10.101.20.165:/srv/airflow/dags/

# 2. Optional: Rename to replace v1
ssh rocky@10.101.20.165
cd /srv/airflow/dags
mv ha_service_health_monitor_enhanced.py ha_service_health_monitor_enhanced_v1_backup.py
mv ha_service_health_monitor_enhanced_v2.py ha_service_health_monitor_enhanced.py

# 3. Wait 30 seconds for DAG to appear in UI

# 4. Test it!
```

---

## üìã What v2 Logs Look Like

### When Service Fails (Example):

```
üö® CRITICAL: airflow-worker on celery-1 is inactive (should be ACTIVE)!

üîç Searching for task-specific logs using pattern: check_celery_1_airflow_worker|manual__2025-10-28T11:30:22|12345
   Task identifiers:
     - dag_id: ha_service_health_monitor_enhanced
     - task_id: check_celery_1_airflow_worker
     - run_id: manual__2025-10-28T11:30:22.050978+00:00
     - job_id: 12345
     - external_executor_id: abc-123-celery-task
     - ti_key: ha_service_health_monitor_enhanced__check_celery_1_airflow_worker__2025-10-28 11:30:22
     - pid: 67890

================================================================================
üìã SERVICE LOGS (journalctl - last 2 minutes):
================================================================================
2025-10-28T14:59:30+0330 celery-1 systemd[1]: airflow-worker.service: Main process exited
2025-10-28T14:59:30+0330 celery-1 systemd[1]: airflow-worker.service: Failed with result 'exit-code'
2025-10-28T14:59:35+0330 celery-1 systemd[1]: Stopped Airflow celery worker

================================================================================
üìã TASK-SPECIFIC AIRFLOW LOGS (across all components):
================================================================================
üìã Scheduler haproxy-1 logs for this task:
2025-10-28T15:00:27+0330 haproxy-1 airflow-scheduler: Sending task check_celery_1_airflow_worker
2025-10-28T15:00:27+0330 haproxy-1 airflow-scheduler: Task queued on celery

üìã Worker celery-1 logs for this task:
2025-10-28T15:00:31+0330 celery-1 airflow-worker: Executing task check_celery_1_airflow_worker
2025-10-28T15:00:31+0330 celery-1 airflow-worker: Task PID: 67890

================================================================================
üìã THIS TASK'S WORKER LOG:
================================================================================
[2025-10-28, 15:00:31 +0330] {taskinstance.py:1345} INFO - Executing task
[2025-10-28, 15:00:31 +0330] {logging_mixin.py:188} INFO - üîç Checking airflow-worker remotely
[2025-10-28, 15:00:32 +0330] {logging_mixin.py:188} INFO - ‚ùå Service is inactive
```

**Key improvements:**
- ‚úÖ Task identifiers clearly shown
- ‚úÖ No "[Invalid date]" - all timestamps properly formatted
- ‚úÖ Logs from last 2 minutes only (concise)
- ‚úÖ Traces task across schedulers AND workers
- ‚úÖ Shows PID, job_id, external_executor_id for debugging

---

## üéì Understanding Airflow Logs (Your Question)

### You asked about "Pre task execution logs" and "Post task execution logs"

**Pre task execution logs (‚ñ∂ Pre task execution logs):**
- Generated automatically by Airflow BEFORE your code runs
- Contains: dependency checks, task queuing, resource allocation
- You don't control this - Airflow generates it

**Main task body (no collapsible header):**
- YOUR code output - your print() statements
- This is where you see diagnostic logs in v2

**Post task execution logs (‚ñ∂ Post task execution logs):**
- Generated automatically by Airflow AFTER your code runs
- Contains: return values, XCom operations, task status
- You don't control this - Airflow generates it

**See AIRFLOW_LOGS_EXPLAINED.md for full details**

---

## ‚úÖ Verification Checklist

After deploying v2, verify:

- [ ] DAG shows in UI with `v2` tag
- [ ] Schedule is `*/2 * * * *` (every 2 minutes)
- [ ] detect_nfs_active_node correctly identifies active NFS
- [ ] Active NFS services pass (‚úÖ)
- [ ] Passive NFS services show "‚è∏Ô∏è EXPECTED" (fail but expected)
- [ ] DAG succeeds when only passive services fail
- [ ] DAG fails when critical services fail
- [ ] Failed task logs show task identifiers
- [ ] No "[Invalid date]" in timestamps
- [ ] No deprecation warnings
- [ ] Timestamps show +0330 (Asia/Tehran)

---

## üìä Comparison: v1 vs v2

| Feature | v1 (Broken) | v2 (Fixed) |
|---------|-------------|------------|
| NFS Logic | ‚ùå Active node checks fail | ‚úÖ Works correctly |
| Schedule | 15 minutes | ‚úÖ 2 minutes |
| Log Duration | 60 minutes (too large) | ‚úÖ 2 minutes |
| Task Tracing | ‚ùå Basic | ‚úÖ Cross-component with identifiers |
| Timestamps | ‚ùå "[Invalid date]" | ‚úÖ Proper ISO format +0330 |
| Deprecation Warnings | ‚ùå Yes | ‚úÖ None |
| Log Size | ‚ùå Too large | ‚úÖ Concise |

---

## üìÅ File Download Links

### Core Files (Use These):
1. [**ha_service_health_monitor_enhanced_v2.py**](computer:///mnt/user-data/outputs/ha_service_health_monitor_enhanced_v2.py) ‚≠ê **START HERE**
2. [**V2_FIXES_SUMMARY.md**](computer:///mnt/user-data/outputs/V2_FIXES_SUMMARY.md) - What changed and why
3. [**AIRFLOW_LOGS_EXPLAINED.md**](computer:///mnt/user-data/outputs/AIRFLOW_LOGS_EXPLAINED.md) - Log structure explained

### Supporting Docs:
4. [**DEPLOYMENT_GUIDE.md**](computer:///mnt/user-data/outputs/DEPLOYMENT_GUIDE.md) - How to deploy
5. [**TIMEZONE_CONFIGURATION_GUIDE.md**](computer:///mnt/user-data/outputs/TIMEZONE_CONFIGURATION_GUIDE.md) - Timezone setup
6. [**QUICK_REFERENCE.md**](computer:///mnt/user-data/outputs/QUICK_REFERENCE.md) - Quick commands

---

## üÜò If You Have Issues

1. **Read V2_FIXES_SUMMARY.md** - Explains all fixes in detail
2. **Read AIRFLOW_LOGS_EXPLAINED.md** - Answers your log structure questions
3. **Check verification checklist above** - Make sure all items pass
4. **Compare your logs with examples** - In V2_FIXES_SUMMARY.md

---

## üéâ Summary

**Version 2 (v2) is ready for production:**
- ‚úÖ All 4 issues fixed
- ‚úÖ NFS active/passive logic works
- ‚úÖ 2-minute monitoring
- ‚úÖ Enhanced task tracing
- ‚úÖ Clean timestamps
- ‚úÖ No warnings
- ‚úÖ Comprehensive logging

**Deploy the v2 file and test it!** 

The logs will now show exactly what you requested - task identifiers, proper timestamps, and logs from all relevant components for failed services.
